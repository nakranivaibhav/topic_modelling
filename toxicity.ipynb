{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-family: 'Bebas Neue'; font-size:1.2em;\">To be Implemented</span>\n",
    "\n",
    "<span style=\"font-family: 'Bebas Neue'; font-size:1.2em;\">Could not run due to memory issues</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import words\n",
    "import string\n",
    "punct = set(string.punctuation)\n",
    "eng_set = set(words.words())\n",
    "\n",
    "def clean_text(text:str):\n",
    "    \"\"\"\n",
    "    Removes emojis, double quotation marks, and other non-word characters, \n",
    "    keeping only English words.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text string.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned text with only English words and spaces.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):  # Check if the input is a float\n",
    "        text = str(text)\n",
    "    #Lower case all text\n",
    "    text = text.lower()\n",
    "    \n",
    "    if isinstance(text, float):  # Check if the input is a float\n",
    "        text = str(text)\n",
    "    # 1. Emoji Removal:\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # Symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # Transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # Flags \n",
    "        u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "        u\"\\U000024C2-\\U0001F251\"  # Enclosed characters\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    text = emoji_pattern.sub(r'', text) \n",
    "\n",
    "    # 2. Remove double quotation marks:\n",
    "    text = text.replace('\"', '')\n",
    "\n",
    "    #Remove mentions\n",
    "    pattern = r\"@\\w+\"\n",
    "\n",
    "    text = re.sub(pattern, '', text)\n",
    "\n",
    "    #Clean single letters and numbers\n",
    "    pattern = r'(\\d+)'\n",
    "\n",
    "    text = re.sub(pattern, '', text)\n",
    "\n",
    "    # Remove Punctuations\n",
    "    text = \" \".join([word for word in text.split() if word not in punct])\n",
    "    \n",
    "    #Only words in english language\n",
    "    text = \" \".join([word for word in text.split() if word.lower() in eng_set])\n",
    "    \n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "\n",
    "url = 'https://drive.google.com/uc?id=1DcWCYXWuFmWNqlqfJT8L1OpaYuuzaI9e'\n",
    "output = 'final_df.csv'\n",
    "\n",
    "gdown.download(url, output, quiet=False)\n",
    "\n",
    "df = pd.read_csv(output)\n",
    "df['clean_text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'Bebas Neue'; font-size:1.2em;\">Labelling toxic and non-toxic posts</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_column = 'clean_text'\n",
    "model_name = 's-nlp/roberta_toxicity_classifier'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.clean_text.to_list()\n",
    "if isinstance(text, str):\n",
    "    text = [text]\n",
    "elif isinstance(text, pd.Series):\n",
    "    text = text.tolist()\n",
    "\n",
    "text = [str(t) for t in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text data\n",
    "inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.argmax(outputs.logits, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: 'Bebas Neue'; font-size:1.2em;\">After the comments are labelled. Further Label them with granularity</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_column = 'text'\n",
    "model_name = 'unitary/toxic-bert'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize the text data\n",
    "inputs = tokenizer(df[text_column].tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "# Add predicted labels to the DataFrame\n",
    "# df[label_column] = [1 if label != -1 else 0 for label in predictions.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at the discourse of toxicity through time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To be implemented"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
